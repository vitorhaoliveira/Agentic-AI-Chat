# Agentic AI Chat System

An intelligent chat assistant powered by autonomous AI agents (not workflows) with custom orchestration. The system can answer questions about weather, currency exchange rates, and PDF documents in Portuguese and English.

## Features

- ðŸ¤– **Autonomous Agents**: Dynamic decision-making with custom lightweight orchestration
- ðŸŒ¤ï¸ **Weather Information**: Real-time weather data via Open-Meteo (accent-aware)
- ðŸ’± **Currency Exchange**: Live exchange rates with Portuguese support (dÃ³lar, real, euro)
- ðŸ“„ **PDF Search**: Upload and query PDF documents with TF-IDF indexing
- âš¡ **Real-time Streaming**: Server-Sent Events (SSE) for live responses
- ðŸŽ¨ **Modern UI**: Beautiful interface with Tailwind CSS and shadcn/ui
- ðŸ” **Authentication**: JWT-based auth (mock for demo)
- ðŸŒ **Bilingual**: Full support for Portuguese and English queries

## Architecture

This is a **monorepo** with npm workspaces:

```
the-project/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ web/          # React + Vite frontend
â”‚   â””â”€â”€ api/          # Express + Custom Agent System backend
â”œâ”€â”€ packages/
â”‚   â””â”€â”€ shared/       # Shared TypeScript types and Zod schemas
â””â”€â”€ docs/
    â”œâ”€â”€ architecture.md          # Detailed architecture documentation
    â””â”€â”€ architecture-diagram.md  # ðŸ“Š Mermaid diagrams (visual architecture)
```

**ðŸ“Š [View Architecture Diagrams](docs/architecture-diagram.md)** - Complete visual architecture with 10 interactive Mermaid diagrams covering:
- System overview
- **Agent orchestration flow** (core focus)
- State transitions
- Component hierarchy
- Streaming sequences
- Tool architecture

### Tech Stack

**Frontend**:
- React 18, Vite, TypeScript
- Tailwind CSS, shadcn/ui
- Zustand (state management - separated stores)
- React Query (data fetching)
- React Router (routing with lazy loading)
- react-hot-toast (notifications)
- react-error-boundary (error handling)
- Vitest (testing framework)

**Backend**:
- Node.js, Express, TypeScript
- Custom Agent Orchestration (lightweight, no LangGraph)
- Groq Llama 3.3 70B (Free LLM with ultra-fast streaming) âš¡
- Pino (structured logging)
- Vitest (testing framework)
- pdf-parse (PDF extraction)
- TF-IDF indexing (persisted to JSON)

**External APIs**:
- Open-Meteo (weather)
- open.er-api.com (currency)

## Quick Start

### Prerequisites

- Node.js 18+
- Groq API key (free at https://console.groq.com)

### Installation

```bash
# Install all dependencies
npm install

# Create .env file in apps/api
cat > apps/api/.env << EOF
PORT=3001
NODE_ENV=development
GROQ_API_KEY=your_groq_api_key_here
JWT_SECRET=your_secret_key_here
DATA_DIR=./data
EOF
```

**Get your FREE Groq API key:**
1. Visit https://console.groq.com
2. Sign up (free)
3. Generate an API key
4. Add it to `apps/api/.env`

**Why Groq?**
- âœ… **100% Free** - 14,400 requests/day
- âœ… **Extremely Fast** - Up to 10x faster than GPT-4
- âœ… **No Credit Card** - No billing required
- âœ… **Production Ready** - Powers many apps

### Development

```bash
# Start both frontend and backend
npm run dev

# Or start separately:
npm run dev:web    # Frontend on http://localhost:3000
npm run dev:api    # Backend on http://localhost:3001
```

### Build

```bash
# Build all workspaces
npm run build
```

## Usage

1. **Login**: Use any username (min 3 chars) and password (min 6 chars)
2. **Upload PDF**: Click "Attach PDF" button in the chat input
3. **Ask Questions**:
   - "What's the weather in SÃ£o Paulo?"
   - "Convert 100 USD to EUR"
   - "Search for [topic] in my PDF"

### ðŸ“„ How to Use PDF Attachments (ChatGPT-style)

1. Click "Attach PDF" button in the chat input
2. Select a PDF file (max 10MB)
3. The PDF preview appears above the input
4. Type your question and press Send
5. The AI reads the PDF and answers your question

**Examples:**
- "What is this document about?"
- "Summarize the main points"
- "Find information about [topic] in this PDF"
- "O que diz este documento?"

**Note:** PDFs are processed on-demand and not stored permanently. Attach a new PDF for each conversation.

**âš ï¸ Important:** PDFs must have **selectable text**. Scanned PDFs (images) won't work. Use OCR tools like [ilovepdf.com/ocr-pdf](https://www.ilovepdf.com/ocr-pdf) to convert scanned PDFs first.

See **[PDF_TROUBLESHOOTING.md](PDF_TROUBLESHOOTING.md)** if you get "cannot read PDF" errors.

## Agent System

The system uses a **custom lightweight agent orchestration** (no external dependencies):

```
User Query â†’ Router Agent (LLM) â†’ [Weather/Currency/PDF] Agent â†’ Synthesizer (Llama 3.3 70B) â†’ Response
```

**Key Difference from Workflows**:
- âŒ Workflow: Fixed sequence (A â†’ B â†’ C)
- âœ… Agents: Dynamic decisions based on query

**How it works**:
- **Router Agent**: Uses LLM to analyze intent (not keyword-based!)
- **Tool Selection**: Dynamically chooses weather/currency/PDF tool
- **Entity Extraction**: LLM extracts locations, currencies, etc.
- **Synthesis**: Streams response with SSE
- **Bilingual**: Works with Portuguese and English queries

Agents autonomously decide what tools to use based on the user's query.

**Example Flow**:
1. User: "qual a cotaÃ§Ã£o do dÃ³lar?"
2. Router â†’ Llama 3.3 analyzes â†’ "currency intent detected"
3. Currency Agent â†’ Llama 3.3 extracts â†’ "FROM:USD TO:BRL"
4. API call â†’ Exchange rate retrieved
5. Synthesizer â†’ Llama 3.3 streams â†’ "1 USD = 5.23 BRL"

## Project Structure

### Frontend (apps/web)

```
src/
â”œâ”€â”€ config/              # Centralized configuration
â”‚   â””â”€â”€ app.config.ts
â”œâ”€â”€ utils/               # Utilities
â”‚   â”œâ”€â”€ logger.ts        # Structured logging
â”‚   â””â”€â”€ toast.ts         # Toast notifications
â”œâ”€â”€ services/            # Business logic layer
â”‚   â”œâ”€â”€ api.service.ts          # API client
â”‚   â”œâ”€â”€ storage.service.ts      # LocalStorage abstraction
â”‚   â”œâ”€â”€ fileValidation.service.ts
â”‚   â”œâ”€â”€ conversation.service.ts
â”‚   â””â”€â”€ __tests__/       # Service tests
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ErrorBoundary.tsx       # Global error boundary
â”‚   â”œâ”€â”€ sidebar/         # Sidebar components (6)
â”‚   â”œâ”€â”€ ui/              # shadcn/ui components
â”‚   â”œâ”€â”€ chat/            # Chat components
â”‚   â”œâ”€â”€ auth/            # Authentication
â”‚   â””â”€â”€ modals/          # Modal components
â”œâ”€â”€ store/               # Zustand stores (separated)
â”‚   â”œâ”€â”€ conversationStore.ts    # Conversation management
â”‚   â”œâ”€â”€ messageStore.ts         # Message management
â”‚   â””â”€â”€ authStore.ts
â”œâ”€â”€ hooks/               # Custom hooks
â”œâ”€â”€ lib/                 # API client, utilities
â””â”€â”€ pages/               # Route pages
```

### Backend (apps/api)

```
src/
â”œâ”€â”€ config/              # Centralized configuration
â”‚   â”œâ”€â”€ app.config.ts    # App settings
â”‚   â”œâ”€â”€ llm.config.ts    # LLM configuration
â”‚   â””â”€â”€ logger.config.ts # Logging setup
â”œâ”€â”€ express/             # Express server
â”‚   â”œâ”€â”€ server.express.ts  # Main server
â”‚   â”œâ”€â”€ routes/          # API routes
â”‚   â”‚   â”œâ”€â”€ auth.express.ts      # Authentication
â”‚   â”‚   â”œâ”€â”€ chat.express.ts      # Chat streaming
â”‚   â”‚   â””â”€â”€ pdf.express.ts       # PDF management
â”‚   â”œâ”€â”€ middleware/      # Express middleware
â”‚   â”‚   â””â”€â”€ auth.express.ts      # JWT authentication
â”‚   â””â”€â”€ utils/           # Express utilities
â”‚       â””â”€â”€ sse-stream.express.ts  # SSE helpers
â”œâ”€â”€ middleware/          # Error handling
â”‚   â””â”€â”€ error-handler.middleware.ts
â”œâ”€â”€ prompts/             # LLM prompt templates
â”‚   â””â”€â”€ agent-prompts.ts
â”œâ”€â”€ agents/              # Agent orchestration
â”‚   â”œâ”€â”€ state.ts         # Agent state
â”‚   â””â”€â”€ graph.ts         # Agent graph
â”œâ”€â”€ tools/               # Tool implementations
â”‚   â”œâ”€â”€ weather.ts       # Weather API
â”‚   â”œâ”€â”€ currency.ts      # Currency API
â”‚   â””â”€â”€ pdf-reader.ts    # PDF search
â””â”€â”€ services/            # Core services
    â”œâ”€â”€ llm.ts           # Groq client (Llama 3.3)
    â””â”€â”€ pdf-index.ts     # TF-IDF indexing
```

### Shared (packages/shared)

```
src/
â”œâ”€â”€ types/               # TypeScript types
â””â”€â”€ schemas/             # Zod validation schemas
```

## Documentation

- **[ðŸ“Š Architecture Diagrams](docs/architecture-diagram.md)** - Visual architecture with Mermaid diagrams
- [Architecture Guide](docs/architecture.md) - Detailed system architecture
- [Frontend README](apps/web/README.md) - Frontend documentation
- [Backend README](apps/api/README.md) - Backend documentation

## Features in Detail

### Real-time Streaming

The chat uses Server-Sent Events (SSE) to stream Llama 3.3 tokens in real-time with ultra-fast responses from Groq's infrastructure.

### PDF Indexing

PDFs are indexed using TF-IDF (Term Frequency-Inverse Document Frequency):
- Efficient keyword-based search
- Extracts relevant excerpts
- Persisted to `data/pdf-index.json`
- Can be upgraded to vector embeddings for semantic search

### Agent Orchestration

Custom lightweight orchestration manages the agent workflow:
1. **Router**: LLM analyzes intent and routes to appropriate tool
2. **Tool Agents**: LLM extracts entities (location, currency, etc.), executes tasks
3. **Synthesizer**: Llama 3.3 70B streams natural response via SSE

**Key Features**:
- âœ… No external dependencies (removed LangGraph)
- âœ… **LLM-based routing** (not keyword-based!)
- âœ… **LLM-based entity extraction** for flexible queries
- âœ… Portuguese and English support
- âœ… Smart geocoding with Brazilian context awareness
- âœ… Professional value formatting (4 decimals for rates, 2 for amounts)
- âœ… **Ultra-fast streaming** (token-by-token from Groq)

Agents operate autonomously - no fixed workflow!

## Scripts

```bash
npm run dev          # Start frontend + backend
npm run dev:web      # Start frontend only
npm run dev:api      # Start backend only
npm run build        # Build all workspaces
npm run lint         # Lint all workspaces
npm run format       # Format with Prettier
```

## Environment Variables

**Backend** (`apps/api/.env`):
```env
PORT=3001
NODE_ENV=development
GROQ_API_KEY=your_groq_api_key
JWT_SECRET=your_secret_key
DATA_DIR=./data
```
**Metrics**:
- ChatPage: 195 â†’ 70 lines (-65%)
- Components: +600% (sidebar componentization)
- Test Coverage: 0 â†’ 2 test suites

## License

MIT

## Cost & Performance

**Groq Costs** (Llama 3.3 70B):
- âœ… **$0.00** - Completely FREE
- âœ… **14,400 requests/day** - Generous free tier
- âœ… **No credit card required**
- âœ… **No hidden costs**

**Why Groq + Llama 3.3?**
- âœ… **100% Free** - Perfect for portfolios
- âœ… **Ultra Fast** - 10x faster than GPT-4
- âœ… **Open Source** - Llama 3.3 70B model (newest version!)
- âœ… **Production Ready** - Used by thousands of apps
- âœ… **High Quality** - Comparable to GPT-4

**Performance**:
- Average response time: <1 second
- Streaming latency: ~50ms
- Tokens per second: 200-400 (extremely fast!)

## Acknowledgments

- [Groq](https://groq.com) - Ultra-fast LLM inference (Free!)
- [Meta AI](https://ai.meta.com) - Llama 3.3 70B model
- [Open-Meteo](https://open-meteo.com) - Weather API
- [ExchangeRate-API](https://www.exchangerate-api.com) - Currency API
- [shadcn/ui](https://ui.shadcn.com) - UI components
- [Express](https://expressjs.com) - HTTP server

